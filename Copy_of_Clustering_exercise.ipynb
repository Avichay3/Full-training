{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avichay3/Full-training/blob/main/Copy_of_Clustering_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g02uyRKMJdL_"
      },
      "source": [
        "# **Ex1 - Unsupervised learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSqx1-GWJcDY"
      },
      "source": [
        "## Names and IDs\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "## URL for the Colab notebook:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fdcpdvZMdJs"
      },
      "source": [
        "**Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E565M8V0JiPx"
      },
      "source": [
        "In this assignment, we will focus on the practical application of unsupervised learning methods, specifically K-means clustering and Principal Component Analysis (PCA). The primary objective is to deepen your understanding of these algorithms and develop proficiency in their implementation using Python and relevant libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmZgvCtuMgfM"
      },
      "source": [
        "**Learning Objectives:**\n",
        "1.   **Load Local Files**: Implement techniques for\n",
        "     loading datasets from a local file system into Python.\n",
        "3.   **Data Visualization**: Apply various visualization techniques to interpret and present your data analysis findings effectively.\n",
        "4.   **Use Scikit-learn for K-means Clustering**: Use the Scikit-learn library to apply the K-means clustering algorithm.\n",
        "5.   **Use Scikit-learn PCA**: Utilize PCA from Scikit-learn to perform dimensionality reduction, a critical technique for analyzing high-dimensional data.\n",
        "6.   **Algoritmic Understendig**: Solve the calculation problem whle using the algorithms learned in class.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d35uo61hMmPG"
      },
      "source": [
        "\n",
        "**Important Guidelines:**\n",
        "\n",
        "**Thoroughly Read the Task Before Implementation:** Ensure to understand the entire assignment and its requirements before beginning to code. A comprehensive understanding will aid in a more structured and efficient approach to the tasks.\n",
        "\n",
        "**Code Reusability and Function Writing:** Focus on writing reusable code and functions. This practice is crucial for maintaining an organized, efficient, and easily debuggable codebase.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQqIK7IkOXUK"
      },
      "source": [
        "This assignment is designed to enhance both your theoretical understanding and practical skills in key areas of machine learning. Approach each task with diligence and attention to detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esbc-ZiCO60h"
      },
      "source": [
        "## Import All Packages\n",
        "Add all imports needed for this notebook to run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLufnb-KI64u"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id0KErgL0csL"
      },
      "source": [
        "## Prepare Kaggle Load\n",
        "Navigate to https://www.kaggle.com. Then go to the Account tab of your user profile and under settings find \"API\" and then click **Create New Token**. This will trigger the download of kaggle.json, a file containing your API credentials.\n",
        "Then run the cell below and click the upload button to upload kaggle.json to your Colab runtime.\n",
        "\n",
        "* If you don't use Colab, save the files locally using relative paths.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "-n9BOWHk1XG2",
        "outputId": "db1b0b59-fef4-488e-d8ff-3542e61833ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8688d152-6e97-4c22-8bfe-1f163699ecc1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8688d152-6e97-4c22-8bfe-1f163699ecc1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 62 bytes\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# upload kaggle.json file using user prompt\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdA3yb_H1XaI"
      },
      "source": [
        "After uploading the kaggle.json select the data to upload (costumers segmentation in this example). The dataset will be copy to the enviroment in the '/content' directory. You will see the 'Retail.xlsx'.\n",
        "For more about the dataset you can read [here](https://www.kaggle.com/datasets/yasserh/customer-segmentation-dataset/data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYwISu8H0fhw",
        "outputId": "4b7d97df-6b4c-4d3f-fcde-d8752af26c4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/yasserh/customer-segmentation-dataset\n",
            "License(s): CC0-1.0\n",
            "customer-segmentation-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  /content/customer-segmentation-dataset.zip\n",
            "  inflating: Online Retail.xlsx      \n"
          ]
        }
      ],
      "source": [
        "# download the dataset\n",
        "!kaggle datasets download -d yasserh/customer-segmentation-dataset\n",
        "\n",
        "# extract the files\n",
        "!unzip '/content/customer-segmentation-dataset.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8ssPm39Q5-6"
      },
      "source": [
        "## 1. Visualization (9 points)\n",
        "In this section, your task is to create and analyze **three** insightful visualizations based on the customer segmentation dataset. The purpose of these visualizations is to uncover underlying patterns and trends in the data that can inform strategic decisions. Your ability to interpret these visualizations will be key in understanding customer behaviors and preferences.\n",
        "\n",
        "Excel file can be loaded using pandas like this:\n",
        "`df = pd.read_excel('/content/Online Retail.xlsx')`\n",
        "\n",
        "*   You will get 2 points for the graph and 1 for the insight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwd7T5K-Q5ap"
      },
      "outputs": [],
      "source": [
        "# load the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q01Pg0E4aGZd"
      },
      "outputs": [],
      "source": [
        "# Graph 1 -\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sWW3XfQX5_Y"
      },
      "source": [
        "**Insight** -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDC-WccATcUJ"
      },
      "outputs": [],
      "source": [
        "# Graph 2 -\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Luq8ewBWWsX"
      },
      "source": [
        "**Insight** -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jIXZXKSTd4w"
      },
      "outputs": [],
      "source": [
        "# Graph 3 -\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf0OCdmf5VZe"
      },
      "source": [
        "**Insight** -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4D5IfkoQpsB"
      },
      "source": [
        "## 2. KMEANS (20 points)\n",
        "\n",
        "In this exercise, you will implement K-means clustering on a comprehensive customer dataset, to identify distinct customer segments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuMf37LmjLEL"
      },
      "source": [
        "*   Load the data again.\n",
        "*   Scale the data using minmax scaler (1 points).\n",
        "*   Encode categorical variables (3 points).\n",
        "*   Apply k-Means algorithm on the 'MntMeatProducts' and 'MntWines' features using n_clusters=5\n",
        " (4 points).\n",
        "*   Visualize the clusters (3 points).\n",
        "*   Apply k-Means algorithm on all features and find the best k using 2 methods (5 points).\n",
        "*   Visualize the methods (4 points).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8Z3hdGKQpaR"
      },
      "outputs": [],
      "source": [
        "# load the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANNPxKACQnwL"
      },
      "outputs": [],
      "source": [
        "# Scale the data using MinMaxScaler\n",
        "\n",
        "# Encode categorical variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aigS0ZlGlBPn"
      },
      "outputs": [],
      "source": [
        "# Apply k-Means on the 'MntWines' and 'MntMeatProducts' features with n_clusters=5\n",
        "\n",
        "# Visualize the clusters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfPU_uMSpZ9l"
      },
      "source": [
        "### Elbow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMPFkb91pZDD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSev7vbfqTw7"
      },
      "source": [
        "### Silhouette Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-NuZmpIsJNA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wefQVfhtCKs"
      },
      "source": [
        "## 3. PCA (8 points)\n",
        "In this exercise, you will use PCA:\n",
        "*   With n_components = 2 (3 points).\n",
        "*   Visualize the PCA (2 points).\n",
        "*   Find the variance explined in this PCA (3 points).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVdzsODntCpd"
      },
      "outputs": [],
      "source": [
        "# Adjust n_components as needed\n",
        "\n",
        "\n",
        "# Create a DataFrame with the principal components\n",
        "\n",
        "\n",
        "\n",
        "# Plotting the PCA\n",
        "\n",
        "\n",
        "# Display explained variance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8fTt4Kl00C7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQTAlkFn040l"
      },
      "source": [
        "**Q**: What is the variance explained in the 2 component PCA?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmuwM57w1XY2"
      },
      "source": [
        "**A**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FBNDN4M1_5R"
      },
      "source": [
        "## 4. PCA & Kmeans (11 points)\n",
        "This time, we will use the PCA computed output for the kmeans model.\n",
        "*   Run PCA with n_components = 2 (1 points)\n",
        "*   Find the best k for kmeans (4 points)\n",
        "*   Plot the best clusters (3 points)\n",
        "*   Answer the question (What question?) (3 points)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g567KKzSzWYE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNRbRYwQ3F1p"
      },
      "source": [
        "### Elbow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MacHJeVg3DUM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G79RYqGx3SX5"
      },
      "source": [
        "### Silhouette"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHgwpNnK3MHw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr9Czzz74Zrc"
      },
      "source": [
        "**Q**: In our human eye, it's looks like we need 5 clusters. But both methods return 2. Why do you think kmeans returning 2 and not 5?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQKf6VCk4szz"
      },
      "source": [
        "**A**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loZG5mEKVAqJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIXBX71dV0sP"
      },
      "source": [
        "**Questions**:\n",
        "1.   How did the points group together in the final iteration?\n",
        "2.   Was choosing different initial cluster centers leading to different final clusters? Why might this happen?\n",
        "3.   Think of any real-world scenarios where K-means clustering could be useful?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a__DebSWTL-"
      },
      "source": [
        "**Answers**:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xXeEwMkf3GM"
      },
      "source": [
        "## 5. Find 3 datasets online (from kaggle, UCI, etc.) with more than 10 features and include labels - add links to datasets. (37 points)\n",
        "\n",
        "a. Use PCA and TSNE (two different methods) with 2 components each and show the data with their labels (for each of the 3 data sets). 10 points\n",
        "\n",
        "b. Use 3 different clustering methods for each dataset and show plots. Explain which had best results when comparing to labels and why. 12 points\n",
        "\n",
        "c. Explain some of the differences between PCA and TSNE, while addressing the addition of data to the dataset in each. 8 points\n",
        "\n",
        "d. Run datasets with LDA and show plot, how did this method effect results and why? 7 points\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuMpJEjm6Sm2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "uNRbRYwQ3F1p",
        "G79RYqGx3SX5"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}