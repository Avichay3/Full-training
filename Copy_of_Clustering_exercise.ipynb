{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avichay3/Full-training/blob/clustering---exercise/Copy_of_Clustering_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g02uyRKMJdL_"
      },
      "source": [
        "# **Ex1 - Unsupervised learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSqx1-GWJcDY"
      },
      "source": [
        "## Names and IDs\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "## URL for the Colab notebook:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fdcpdvZMdJs"
      },
      "source": [
        "**Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E565M8V0JiPx"
      },
      "source": [
        "In this assignment, we will focus on the practical application of unsupervised learning methods, specifically K-means clustering and Principal Component Analysis (PCA). The primary objective is to deepen your understanding of these algorithms and develop proficiency in their implementation using Python and relevant libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmZgvCtuMgfM"
      },
      "source": [
        "**Learning Objectives:**\n",
        "1.   **Load Local Files**: Implement techniques for\n",
        "     loading datasets from a local file system into Python.\n",
        "3.   **Data Visualization**: Apply various visualization techniques to interpret and present your data analysis findings effectively.\n",
        "4.   **Use Scikit-learn for K-means Clustering**: Use the Scikit-learn library to apply the K-means clustering algorithm.\n",
        "5.   **Use Scikit-learn PCA**: Utilize PCA from Scikit-learn to perform dimensionality reduction, a critical technique for analyzing high-dimensional data.\n",
        "6.   **Algoritmic Understendig**: Solve the calculation problem whle using the algorithms learned in class.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d35uo61hMmPG"
      },
      "source": [
        "\n",
        "**Important Guidelines:**\n",
        "\n",
        "**Thoroughly Read the Task Before Implementation:** Ensure to understand the entire assignment and its requirements before beginning to code. A comprehensive understanding will aid in a more structured and efficient approach to the tasks.\n",
        "\n",
        "**Code Reusability and Function Writing:** Focus on writing reusable code and functions. This practice is crucial for maintaining an organized, efficient, and easily debuggable codebase.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQqIK7IkOXUK"
      },
      "source": [
        "This assignment is designed to enhance both your theoretical understanding and practical skills in key areas of machine learning. Approach each task with diligence and attention to detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esbc-ZiCO60h"
      },
      "source": [
        "## Import All Packages\n",
        "Add all imports needed for this notebook to run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LLufnb-KI64u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id0KErgL0csL"
      },
      "source": [
        "## Prepare Kaggle Load\n",
        "Navigate to https://www.kaggle.com. Then go to the Account tab of your user profile and under settings find \"API\" and then click **Create New Token**. This will trigger the download of kaggle.json, a file containing your API credentials.\n",
        "Then run the cell below and click the upload button to upload kaggle.json to your Colab runtime.\n",
        "\n",
        "* If you don't use Colab, save the files locally using relative paths.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kaggle.json\n",
        "{\n",
        "  \"username\": \"avichay123\",\n",
        "  \"key\": \"KGAT_11fdfd653010e9506693bd56d9046006\"\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We88FEjZ-Iwb",
        "outputId": "04c9ba0e-ebc3-4178-b105-efe7a235f31c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "tJCyFTF6-UGt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "!kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCC5RFmS-XY4",
        "outputId": "9c14a06a-28c8-49ce-990f-b85e220903de"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                             title                                                     size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------  --------------------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
            "amar5693/screen-time-sleep-and-stress-analysis-dataset          Screen Time, Sleep & Stress Analysis Dataset            787136  2026-02-13 06:56:18.757000           7156        141  1.0              \n",
            "amar5693/student-performance-dataset                            Student Performance Dataset                             177286  2026-02-12 06:04:44.613000           6200         98  1.0              \n",
            "aliiihussain/amazon-sales-dataset                               Amazon_Sales_Dataset                                   1297759  2026-02-01 11:37:12.353000           8722        138  1.0              \n",
            "algozee/heart-decices                                           Heart Disease Prediction Using Machine Learning       10070453  2026-02-22 17:32:58.757000            972         45  1.0              \n",
            "meharshanali/student-dropout-prediction-dataset                 ðŸ“„ Student Dropout Prediction Dataset                    260641  2026-02-22 07:45:08.980000            985         30  1.0              \n",
            "algozee/student-productivity-and-behavior-dataset-20k           Student Productivity & Behavior Dataset (20K)           631991  2026-02-24 08:45:04.133000            641         38  1.0              \n",
            "saidaminsaidaxmadov/chocolate-sales                             Chocolate Sales                                         468320  2026-01-04 14:23:35.490000          24883        446  1.0              \n",
            "sehaj1104/student-productivity-and-digital-distraction-dataset  Student Productivity & Digital Distraction Dataset      631991  2026-02-15 17:59:21.013000           1990         41  1.0              \n",
            "payaldhokane/bmw-global-sales-and-market-data                   BMW Global Sales & Market Data                           19680  2026-02-09 17:19:41.173000           1000         26  1.0              \n",
            "jacksaleeby/global-stock-market-indices-4-6m-rows               Global Stock Market Indices (4.6M+ rows)              73181282  2026-02-22 18:56:48.620000            403         25  1.0              \n",
            "datacodex/e-commerce-sales-data                                 E-commerce Sales Analysis                                42375  2026-02-21 04:39:05.147000            770         34  1.0              \n",
            "coderanand/university-query-priority-classification             University Query Priority Classification                 48987  2026-02-18 05:52:09.533000            366         23  0.9411765        \n",
            "grandmaster07/student-exam-performance-dataset-analysis         Student Exam Performance Dataset Analysis                96178  2026-02-10 09:47:13.350000           1130         37  1.0              \n",
            "debanganghosh/imdb-dataset                                      IMDb Top 1000 Movies Dataset (Ratings, Cast, Genre      179262  2026-02-05 14:24:58.317000            814         29  1.0              \n",
            "waddahali/order-delivery-dataset                                Order Delivery Dataset                                 9395013  2026-02-13 22:28:19.903000            531         25  1.0              \n",
            "emanfatima2/student-academic-performance-analysis-dataset       Student Academic Performance Analysis Dataset           101930  2026-02-11 16:13:49.767000            543         27  1.0              \n",
            "zahranusratt/cs-students-performance-dataset                    CS Students Performance Dataset                           3309  2026-02-17 13:10:44.193000            536         25  1.0              \n",
            "sharmajicoder/gaming-and-mental-health                          Gaming and Mental Health                              69574734  2026-02-13 19:31:15.460000           1175         37  1.0              \n",
            "dmahajanbe23/bmw-global-automotive-sales                        BMW Global Automotive Sales                              55017  2026-02-22 18:18:38.170000            468         29  1.0              \n",
            "sehaj1104/student-placement-prediction-dataset-2026             Student Placement Prediction Dataset 2026              9284226  2026-02-18 03:31:04.780000           1146         29  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-n9BOWHk1XG2"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# upload kaggle.json file using user prompt\n",
        "# uploaded = files.upload()\n",
        "# for fn in uploaded.keys():\n",
        "#  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "# !mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdA3yb_H1XaI"
      },
      "source": [
        "After uploading the kaggle.json select the data to upload (costumers segmentation in this example). The dataset will be copy to the enviroment in the '/content' directory. You will see the 'Retail.xlsx'.\n",
        "For more about the dataset you can read [here](https://www.kaggle.com/datasets/yasserh/customer-segmentation-dataset/data)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5DwXGbu7A611"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYwISu8H0fhw",
        "outputId": "8f95d8a4-1dc2-4b18-922d-bbbd09845502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/yasserh/customer-segmentation-dataset\n",
            "License(s): CC0-1.0\n",
            "customer-segmentation-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  /content/customer-segmentation-dataset.zip\n",
            "replace Online Retail.xlsx? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: Online Retail.xlsx      \n"
          ]
        }
      ],
      "source": [
        "# download the dataset\n",
        "!kaggle datasets download -d yasserh/customer-segmentation-dataset\n",
        "\n",
        "# extract the files\n",
        "!unzip '/content/customer-segmentation-dataset.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8ssPm39Q5-6"
      },
      "source": [
        "## 1. Visualization (9 points)\n",
        "In this section, your task is to create and analyze **three** insightful visualizations based on the customer segmentation dataset. The purpose of these visualizations is to uncover underlying patterns and trends in the data that can inform strategic decisions. Your ability to interpret these visualizations will be key in understanding customer behaviors and preferences.\n",
        "\n",
        "Excel file can be loaded using pandas like this:\n",
        "`df = pd.read_excel('/content/Online Retail.xlsx')`\n",
        "\n",
        "*   You will get 2 points for the graph and 1 for the insight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lwd7T5K-Q5ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e49c8b-f3b2-4313-c4c4-b9ac5fc4bf9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((541909, 8),\n",
              "   InvoiceNo StockCode                          Description  Quantity  \\\n",
              " 0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
              " 1    536365     71053                  WHITE METAL LANTERN         6   \n",
              " 2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
              " 3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
              " 4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
              " \n",
              "           InvoiceDate  UnitPrice  CustomerID         Country  \n",
              " 0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
              " 1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
              " 2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
              " 3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
              " 4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  )"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# load the data\n",
        "import pandas as pd\n",
        "\n",
        "# load the Excel file\n",
        "df = pd.read_excel('/content/Online Retail.xlsx')\n",
        "\n",
        "# quick inspection\n",
        "df.shape, df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q01Pg0E4aGZd"
      },
      "outputs": [],
      "source": [
        "×˜# Graph 1 -\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sWW3XfQX5_Y"
      },
      "source": [
        "**Insight** -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDC-WccATcUJ"
      },
      "outputs": [],
      "source": [
        "# Graph 2 -\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Luq8ewBWWsX"
      },
      "source": [
        "**Insight** -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jIXZXKSTd4w"
      },
      "outputs": [],
      "source": [
        "# Graph 3 -\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf0OCdmf5VZe"
      },
      "source": [
        "**Insight** -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4D5IfkoQpsB"
      },
      "source": [
        "## 2. KMEANS (20 points)\n",
        "\n",
        "In this exercise, you will implement K-means clustering on a comprehensive customer dataset, to identify distinct customer segments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuMf37LmjLEL"
      },
      "source": [
        "*   Load the data again.\n",
        "*   Scale the data using minmax scaler (1 points).\n",
        "*   Encode categorical variables (3 points).\n",
        "*   Apply k-Means algorithm on the 'MntMeatProducts' and 'MntWines' features using n_clusters=5\n",
        " (4 points).\n",
        "*   Visualize the clusters (3 points).\n",
        "*   Apply k-Means algorithm on all features and find the best k using 2 methods (5 points).\n",
        "*   Visualize the methods (4 points).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8Z3hdGKQpaR"
      },
      "outputs": [],
      "source": [
        "# load the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANNPxKACQnwL"
      },
      "outputs": [],
      "source": [
        "# Scale the data using MinMaxScaler\n",
        "\n",
        "# Encode categorical variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aigS0ZlGlBPn"
      },
      "outputs": [],
      "source": [
        "# Apply k-Means on the 'MntWines' and 'MntMeatProducts' features with n_clusters=5\n",
        "\n",
        "# Visualize the clusters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfPU_uMSpZ9l"
      },
      "source": [
        "### Elbow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMPFkb91pZDD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSev7vbfqTw7"
      },
      "source": [
        "### Silhouette Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-NuZmpIsJNA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wefQVfhtCKs"
      },
      "source": [
        "## 3. PCA (8 points)\n",
        "In this exercise, you will use PCA:\n",
        "*   With n_components = 2 (3 points).\n",
        "*   Visualize the PCA (2 points).\n",
        "*   Find the variance explined in this PCA (3 points).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVdzsODntCpd"
      },
      "outputs": [],
      "source": [
        "# Adjust n_components as needed\n",
        "\n",
        "\n",
        "# Create a DataFrame with the principal components\n",
        "\n",
        "\n",
        "\n",
        "# Plotting the PCA\n",
        "\n",
        "\n",
        "# Display explained variance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8fTt4Kl00C7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQTAlkFn040l"
      },
      "source": [
        "**Q**: What is the variance explained in the 2 component PCA?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmuwM57w1XY2"
      },
      "source": [
        "**A**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FBNDN4M1_5R"
      },
      "source": [
        "## 4. PCA & Kmeans (11 points)\n",
        "This time, we will use the PCA computed output for the kmeans model.\n",
        "*   Run PCA with n_components = 2 (1 points)\n",
        "*   Find the best k for kmeans (4 points)\n",
        "*   Plot the best clusters (3 points)\n",
        "*   Answer the question (What question?) (3 points)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g567KKzSzWYE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNRbRYwQ3F1p"
      },
      "source": [
        "### Elbow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MacHJeVg3DUM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G79RYqGx3SX5"
      },
      "source": [
        "### Silhouette"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHgwpNnK3MHw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr9Czzz74Zrc"
      },
      "source": [
        "**Q**: In our human eye, it's looks like we need 5 clusters. But both methods return 2. Why do you think kmeans returning 2 and not 5?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQKf6VCk4szz"
      },
      "source": [
        "**A**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loZG5mEKVAqJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIXBX71dV0sP"
      },
      "source": [
        "**Questions**:\n",
        "1.   How did the points group together in the final iteration?\n",
        "2.   Was choosing different initial cluster centers leading to different final clusters? Why might this happen?\n",
        "3.   Think of any real-world scenarios where K-means clustering could be useful?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a__DebSWTL-"
      },
      "source": [
        "**Answers**:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xXeEwMkf3GM"
      },
      "source": [
        "## 5. Find 3 datasets online (from kaggle, UCI, etc.) with more than 10 features and include labels - add links to datasets. (37 points)\n",
        "\n",
        "a. Use PCA and TSNE (two different methods) with 2 components each and show the data with their labels (for each of the 3 data sets). 10 points\n",
        "\n",
        "b. Use 3 different clustering methods for each dataset and show plots. Explain which had best results when comparing to labels and why. 12 points\n",
        "\n",
        "c. Explain some of the differences between PCA and TSNE, while addressing the addition of data to the dataset in each. 8 points\n",
        "\n",
        "d. Run datasets with LDA and show plot, how did this method effect results and why? 7 points\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuMpJEjm6Sm2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "uNRbRYwQ3F1p",
        "G79RYqGx3SX5"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}